{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport sklearn.linear_model as linear_model\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom IPython.display import HTML, display\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#オブジェクトのカラムの名前と数値のカラムの名前をそれぞれ抽出\n\nquantitative = [f for f in train.columns if train.dtypes[f] != 'object']\nquantitative.remove('SalePrice')\nquantitative.remove('Id')\nqualitative = [f for f in train.columns if train.dtypes[f] == 'object']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(qualitative))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train.isnull().sum().sort_values(ascending = False)/len(train)).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"SalePrice\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe().columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = train[['Id', 'MSSubClass', 'LotArea', 'OverallQual',\n       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n       'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n       'MiscVal', 'MoSold', 'YrSold', 'SalePrice']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a[a[\"SalePrice\"] >= 0.4][\"SalePrice\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ターゲットと相関が高いものたちどうしの相関関係\ntrain[['OverallQual','YearBuilt','YearRemodAdd','MasVnrArea','TotalBsmtSF','1stFlrSF','GrLivArea','FullBath','TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','SalePrice']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#objectのdescribe 一気に全部やると見ずらいから分けてやってみたわ\ntrain[['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd']].describe(include = 'O')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['MasVnrType', 'ExterQual', 'ExterCond', 'Foundation','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual']].describe(include = 'O')      \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n       'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']].describe(include = 'O')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as st\ny = train['SalePrice']\nplt.figure(1); plt.title('Johnson SU')\nsns.distplot(y, kde=False, fit=st.johnsonsu)\nplt.figure(2); plt.title('Normal')\nsns.distplot(y, kde=False, fit=st.norm)\nplt.figure(3); plt.title('Log Normal')\nsns.distplot(y, kde=False, fit=st.lognorm)\n#これを見るとlogをとってみると正規分布に従っているような感じをかもしだしてるわ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#カテゴリデータと目的変数のデータの関係性を見ている\nfor c in qualitative:\n    train[c] = train[c].astype('category')\n    if train[c].isnull().any():\n        train[c] = train[c].cat.add_categories(['MISSING'])\n        train[c] = train[c].fillna('MISSING')\n\ndef boxplot(x, y, **kwargs):\n    sns.boxplot(x=x, y=y)\n    x=plt.xticks(rotation=90)\nf = pd.melt(train, id_vars=['SalePrice'], value_vars=qualitative)\ng = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False, size=5)\ng = g.map(boxplot, \"value\", \"SalePrice\")\n'''\n箱ひげ図を見ることによって目的変数に影響を与えそうな特徴量はどれか見れそー\nExterQualなんか見ると各変数のsalepriceの分布がばらばらだからよさげ\nneghtborhoodもいいっぽいけど変数多すぎてみる気にもならないけど一応あとでみとこ\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train[\"SalePrice\"] , train[\"ExterQual\"].map({\"Ex\" : 4 , \"Gd\" : 3 , \"TA\":2,\"Fa\":1})] , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"ExterQual\"] = df[\"ExterQual\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def anva(frame):\n    anv = pd.DataFrame()\n    anv[\"feature\"] = qualitative #objectのやつ\n    pvals = []\n    for c in qualitative:\n        samples = []\n        for cls in frame[c].unique():\n            s = frame[frame[c] == cls][\"SalePrice\"].values\n            samples.append(s)\n        pval = stats.f_oneway(*samples)[1]#一元配置分散分析を行っている\n        pvals.append(pval)\n    anv['pval'] = pvals\n    return anv.sort_values('pval')\n\na = anva(train)\na[\"disparity\"] = np.log(1./a['pval'].values)\nplt.figure(figsize = (9,9))\nsns.barplot(data = a ,x= 'feature' , y = \"disparity\")\nx = plt.xticks(rotation=90)\n\n'''\n特徴量(neighborhood , street , exterqual等)の影響が小さいというのは各特徴量の変数の目的変数に対する平均は等しくなっているはず\n→平均が一緒だと差が出てこないから影響与えてるかなんてわかんないよ的なやつだよねきっとうん。\nこれは一元配置分散分析によってそうならないとおかしいのかも？？？？？\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#特徴量をエンコーディングしている。\ndef encode(frame ,feature):#1つ1つの特徴量をエンコーディングする関数　frameにはtrain,featureには1つ1つの特徴量が入っている\n    ordering = pd.DataFrame()\n    ordering['val'] = frame[feature].unique()\n    ordering.index = ordering.val\n    ordering['spmean'] = frame[[feature , 'SalePrice']].groupby(feature).mean()[\"SalePrice\"]#特徴量の変数ごとにsalepriceの平均を出している\n    ordering = ordering.sort_values('spmean')#ソートした理由がマジでわかんないソートしなくてもできんだろとかおもうけど違うんか？あ？\n    ordering['ordering'] = range(1,ordering.shape[0]+1)\n    ordering = ordering[\"ordering\"].to_dict()\n    \n    \n    for cat ,o in ordering.items(): #trainに代入するって感じ\n        frame.loc[frame[feature] == cat , feature+'_E'] = o\n        \n        \nqual_encoded = []\nfor q in qualitative:\n    encode(train , q)\n    qual_encoded.append(q+'_E')\nprint(qual_encoded)\n\n'''\n質的変数は目的変数(SalePrice)の平均値に基づく順序に従ってエンコードしている。\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#重要な特徴量を可視化してみてみる・\n\ndef spearman(frame , features):\n    spr = pd.DataFrame()\n    spr[\"feature\"] = features\n    spr[\"spearman\"] = [frame[f].corr(frame[\"SalePrice\"],\"spearman\") for f in features]\n    spr = spr.sort_values('spearman')\n    plt.figure(figsize = (6,0.25*len(features)))\n    sns.barplot(data = spr , y = \"feature\" , x = \"spearman\" , orient = \"h\")\n    \n    \nfeatures = quantitative + qual_encoded\nspearman(train , features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize= (16 , 16))\n#saleprice と　特徴量との相関\nplt.figure(1)\ncorr = train[quantitative + [\"SalePrice\"]].corr()\nsns.heatmap(corr)\n\n\n#saleprice と \nplt.figure(2)\ncorr = train[qual_encoded + [\"SalePrice\"]].corr()\nsns.heatmap(corr)\n\n\nplt.figure(3)\ncorr = pd.DataFrame(np.zeros([len(quantitative) + 1 , len(qual_encoded) +1]) , index = quantitative + [\"SalePrice\"] , columns = qual_encoded + [\"SalePrice\"])\nfor q1 in quantitative + [\"SalePrice\"]:\n    for q2 in qual_encoded + [\"SalePrice\"]:\n        corr.loc[q1 , q2] = train[q1].corr(train[q2])\nsns.heatmap(corr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1)\ncorr = train[quantitative + [\"SalePrice\"]].corr()\nsns.heatmap(corr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pairplot(x, y , **kwargs):\n    ax = plt.gca()\n    ts = pd.DataFrame({\"time\" : x , \"val\" : y})\n    ts = ts.groupby(\"time\").mean()\n    ts.plot(ax = ax)\n    plt.xticks(rotation = 90)\n    \nf = pd.melt(train , id_vars = [\"SalePrice\"] , value_vars = quantitative + qual_encoded)\ng = sns.FacetGrid(f , col = \"variable\" , col_wrap = 2 , sharex = False , sharey = False , size = 5)\ng = g.map(pairplot , \"value\" , \"SalePrice\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"SalePrice\" , \"MoSold\"]].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train[\"MoSold\"] , (train[\"MoSold\"] * train[\"MoSold\"])] , axis = 1 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"SalePrice\"] = train[\"SalePrice\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"SalePrice\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = quantitative\n\nstandard = train[train[\"SalePrice\"] < 200000]#平均よりも小さいものが入っている\npricey = train[train[\"SalePrice\"] >= 200000]#平均よりも値が多きものが入っている。\n\ndiff = pd.DataFrame()\ndiff[\"feature\"] = features\ndiff[\"difference\"] = [(pricey[f].fillna(0.).mean() - standard[f].fillna(0.).mean())/(standard[f].fillna(0.).mean()) for f in features]\n#価格が高いものと価格が低いものとの特徴量の変化のちがいを表している↑\n\nsns.barplot(data = diff , x = \"feature\" , y = \"difference\")\nx = plt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = quantitative + qual_encoded\nmodel = TSNE(n_components = 2 , random_state = 0 , perplexity = 50)\nX = train[features].fillna(0.).values\ntsne = model.fit_transform(X)\n\nstd = StandardScaler()\ns = std.fit_transform(X)\npca = PCA(n_components = 30)\npca.fit(s)\npc = pca.transform(s)\nkmeans = KMeans(n_clusters = 5)\nkmeans.fit(pc)\n\nfr = pd.DataFrame({\"tsne1\":tsne[:,0] , \"tsne2\" : tsne[: , 1] , \"cluster\" : kmeans.labels_})\nsns.lmplot(data = fr , x= \"tsne1\" , y = \"tsne2\" , hue = \"cluster\" , fit_reg = False)\nprint(np.sum(pca.explained_variance_ratio_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train[\"SalePrice\"].values\ndef johnson(y):\n    gamma , eta , epsilon , lbda = stats.johnsonsu.fit(y)\n    yt = gamma + eta*np.arcsinh((y - epsilon) / lbda)\n    return yt ,gamma , eta , epsilon ,lbda\n\ndef johnson_inverse(y , gamma , eta , epsilon , lbda ):\n    return lbda*np.sinh((y - gamma) / eta) + epsilon\n\n\nyt , g , et , ep , l = johnson(y)\nyt2 = johnson_inverse(yt , g , et , ep , l)\nplt.figure(1)\nsns.distplot(yt)\nplt.figure(2)\nsns.distplot(yt2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ここから始めるるるるるる！！\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n%matplotlib inline\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport sklearn.linear_model as linear_model\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom IPython.display import HTML, display\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\ntrain = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/sample_submission.csv\")\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(\"Id\" , axis = 1)\ntest.drop(\"Id\" , axis = 1)\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\ntrain = train.drop(train[(train[\"GrLivArea\"] > 4000) & (train[\"SalePrice\"] < 300000)].index)\nntrain = train.shape[0]\nntest = test.shape[0]\ny_train = train.SalePrice.values\nall_data = pd.concat((train , test)).reset_index(drop = True)\nall_data.drop([\"SalePrice\"] , axis = 1 , inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(all_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending = False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio':all_data_na})\n\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nf , ax = plt.subplots(figsize = (15,12))\nplt.xticks(rotation = 90)\nsns.barplot(all_data_na.index , all_data_na)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = train.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (12,9))\nsns.heatmap(corrmat , vmax = 0.9 , square = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = [\"MiscFeature\" , \"Alley\" , \"Fence\" , \"FireplaceQu\"] \nfor i in k:\n    all_data[i] = all_data[i].fillna(\"None\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x : x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#欠損値を穴埋めする！！！！\nall_data['GarageCars'] = all_data['GarageCars'].fillna(2)\nall_data[\"GarageYrBlt\"] = all_data[\"GarageYrBlt\"].fillna(0)\nall_data['GarageArea'] = all_data['GarageArea'].fillna(0)\nall_data['BsmtFinSF1'] = all_data['BsmtFinSF1'].fillna(0)\nall_data['BsmtFinSF2'] = all_data['BsmtFinSF2'].fillna(0)\nall_data['BsmtUnfSF'] = all_data[ 'BsmtUnfSF'].fillna(0)\nall_data['TotalBsmtSF'] = all_data['TotalBsmtSF'].fillna(988)\nall_data['BsmtFullBath'] = all_data['BsmtFullBath'].fillna(0)\nall_data['BsmtHalfBath'] = all_data['BsmtHalfBath'].fillna(0)\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')\nall_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\nall_data = all_data.drop(['Utilities'], axis=1)\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\nall_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#欠損値がないことを確認する\nall_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#もう少し特徴量エンジニアリング\n#MSSubClass=The building class\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n\n\n#Changing OverallCond into a categorical variable\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\n\n\n#Year and month sold are transformed into categorical features.\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labelencodeで行っている！！\n\n#順序のカテゴリを含んでいるものを数値にエンコーディングしている(ただ単にラベルエンコーディングを行っている)\nfrom sklearn.preprocessing import LabelEncoder\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\n\n#ターゲットエンコーディングで行ってみる\n\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder()\n    lbl.fit(list(all_data[c].values)) \n    all_data[c] = lbl.transform(list(all_data[c].values))\n\n# shape        \nprint('Shape all_data: {}'.format(all_data.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#ターゲットエンコーディングを行ってみる\ntrain = all_data[:ntrain]\ntest = all_data[ntrain:]\n\ncols1 = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\ncols2 = ['FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold']\nimport category_encoders as ce\ntarget_enc = ce.TargetEncoder(cols=cols1)\ntarget_enc.fit(train[cols2], y_train)\n\ntrain[cols2] = target_enc.transform(train[cols2])\ntest[cols2] = target_enc.transform(test[cols2])\n\n\n\nall_data = pd.concat((train , test)).reset_index(drop = True)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#面積のデータは住宅価格に大きく影響を与える\n#そのため各住宅の地下室、1階、2階の面積の合計面積の新しい特徴量を作成する\nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scipy.statsをimportして、skew()で歪度を算出できます。\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n#オブジェクトじゃないカラム名を算出している\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box Cox transformを使用した変換\nskewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    #all_data[feat] += 1\n    all_data[feat] = boxcox1p(all_data[feat], lam)\n    \n#all_data[skewed_features] = np.log1p(all_data[skewed_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.get_dummies(all_data)\nprint(all_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#テストデータとトレーニングデータを元に戻している\ntrain = all_data[:ntrain]\ntest = all_data[ntrain:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# こっから予測を始める","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.linear_model import LinearRegression , RidgeCV , LassoCV , ElasticNetCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#クロスバリデーションを使用する\n#Validation function\nn_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lasso\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n\n#Elastic Net Regression\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n\n#Kernel Ridge Regression\nKRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n\n#Gradient Boosting Regression \nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\n\n#XGBoost\nmodel_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\n\n#LightGBM\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#予測を行う！！\naverage_df = pd.DataFrame()\n\nlasso.fit(train, y_train)\nlasso_pred = np.exp(lasso.predict(test))\naverage_df[\"lasso\"] = lasso_pred\n\nENet.fit(train, y_train)\nENet_pred = np.exp(ENet.predict(test))\naverage_df[\"ENet\"] = ENet_pred\n\nKRR.fit(train, y_train)\nKRR_pred = np.exp(KRR.predict(test))\naverage_df[\"KRR\"] = KRR_pred\n\nGBoost.fit(train, y_train)\nGBoost_pred = np.exp(GBoost.predict(test))\naverage_df[\"GBoost\"] = GBoost_pred\n\nmodel_xgb.fit(train, y_train)\nmodel_xgb_pred = np.exp(model_xgb.predict(test))\naverage_df[\"model_xgb\"] = model_xgb_pred\n\nmodel_lgb.fit(train, y_train)\nmodel_lgb_pred = np.exp(model_lgb.predict(test))\naverage_df[\"model_lgb\"] = model_lgb_pred\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#average_df[\"Ave\"] = average_df.mean(axis=1) \n#average_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#提出データにする\n#sample_submission[\"SalePrice\"] = average_df[\"Ave\"]\n#sample_submission.to_csv('hose_price21.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AveragingModels(BaseEstimator , RegressorMixin , TransformerMixin):\n    \n    def __init__(self ,models):\n        self.models = models\n        \n    def fit(self,X,y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        \n        for model in self.models_:\n            model.fit(X,y)\n            \n        return self\n    \n    \n    def predict(self , X):\n        predictions = np.column_stack([\n            model.predict(X) for model in self.models_\n        ])\n        \n        return np.mean(predictions , axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# ここから予測を始める","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#特徴量を削減する\ncolumns1 = ['TotalBsmtSF','1stFlrSF','2ndFlrSF',\"LandSlope\",\"Street\",\"Functional\" ,\"Alley\",\"SaleType_COD\", 'SaleCondition_Partial',\n            \"RoofStyle_Shed\",\"RoofMatl_WdShngl\",\"Neighborhood_Veenker\",\"MiscFeature_TenC\",\n           \"MasVnrType_Stone\",\"MSZoning_RM\",\"LotConfig_Inside\",\"LandContour_Lvl\",\"HouseStyle_SLvl\",\"Heating_Wall\",\"GarageType_None\"\n           ,\"Foundation_Wood\" , \"Exterior2nd_VinylSd\" , \"Exterior1st_WdShing\",\"Electrical_SBrkr\",\"Condition2_RRNn\",\"Condition1_RRNn\"\n           ,\"BldgType_TwnhsE\",\"BsmtFinSF2\"]\ncombine = [train , test]\n\nfor data in combine:\n    for i in columns1:\n        data.drop(i , axis = 1 , inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\nprint(train_df.shape)\nprint(test_df.shape)\n\n\ntrain_df = train\ntest_df = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_df = pd.DataFrame()\npredict_df = pd.DataFrame()\n\n\nlasso.fit(train, y_train)\nlasso_pred = np.exp(lasso.predict(test))\naverage_df[\"lasso\"] = lasso_pred\nlasso_pred2 = np.exp(lasso.predict(train))\npredict_df[\"lasso\"] = lasso_pred2\n\nENet.fit(train, y_train)\nENet_pred = np.exp(ENet.predict(test))\naverage_df[\"ENet\"] = ENet_pred\nENet_pred2 = np.exp(ENet.predict(train))\npredict_df[\"ENet\"] = ENet_pred2\n\n\nKRR.fit(train, y_train)\nKRR_pred = np.exp(KRR.predict(test))\naverage_df[\"KRR\"] = KRR_pred\nKRR_pred2 = np.exp(KRR.predict(train))\npredict_df[\"KRR\"] = KRR_pred2\n\nGBoost.fit(train, y_train)\nGBoost_pred = np.exp(GBoost.predict(test))\naverage_df[\"GBoost\"] = GBoost_pred\nGBoost_pred2 = np.exp(GBoost.predict(train))\npredict_df[\"GBoost\"] = GBoost_pred2\n\nmodel_xgb.fit(train, y_train)\nmodel_xgb_pred = np.exp(model_xgb.predict(test))\naverage_df[\"model_xgb\"] = model_xgb_pred\nmodel_xgb_pred2 = np.exp(model_xgb.predict(train))\npredict_df[\"model_xgb\"] = model_xgb_pred2\n\nmodel_lgb.fit(train, y_train)\nmodel_lgb_pred = np.exp(model_lgb.predict(test))\naverage_df[\"model_lgb\"] = model_lgb_pred\nmodel_lgb_pred2 = np.exp(model_lgb.predict(train))\npredict_df[\"model_lgb\"] = model_lgb_pred2\n\n#平均を求める\n\naverage_df[\"Ave\"] = average_df.mean(axis=1) \npredict_df[\"Ave\"] = predict_df.mean(axis=1) \n\naverage_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#予測の誤差がどのくらいなのかを計算する\ndef error(actual , predicted):\n    actual = np.log(actual)\n    predicted = np.log(predicted)\n    return np.sqrt(np.sum(np.square(actual - predicted))/len(actual))\n\n\nprint(\"error: {}\".format(error(predict_df[\"Ave\"].values , y_train )))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns = None\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr().sort_values(by = \"BsmtFinSF2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#特徴量を削減した後の誤差を求める\n\n#削除したい特徴量\ncolumns2 = [\"GarageCars\"]\n\ntrain_df = train.copy()\ntest_df = test.copy()\n\ncombine2 = [train_df , test_df]\n\n\n\nfor data in combine2:\n    for i in columns2:\n        data.drop(i , axis = 1 , inplace = True)\n\naverage_df2 = pd.DataFrame()\npredict_df2 = pd.DataFrame()\n\n\nlasso.fit(train_df, y_train)\nlasso_pred = np.exp(lasso.predict(test_df))\naverage_df2[\"lasso\"] = lasso_pred\nlasso_pred2 = np.exp(lasso.predict(train_df))\npredict_df2[\"lasso\"] = lasso_pred2\n\nENet.fit(train_df, y_train)\nENet_pred = np.exp(ENet.predict(test_df))\naverage_df2[\"ENet\"] = ENet_pred\nENet_pred2 = np.exp(ENet.predict(train_df))\npredict_df2[\"ENet\"] = ENet_pred2\n\n\nKRR.fit(train_df, y_train)\nKRR_pred = np.exp(KRR.predict(test_df))\naverage_df2[\"KRR\"] = KRR_pred\nKRR_pred2 = np.exp(KRR.predict(train_df))\npredict_df2[\"KRR\"] = KRR_pred2\n\nGBoost.fit(train_df, y_train)\nGBoost_pred = np.exp(GBoost.predict(test_df))\naverage_df2[\"GBoost\"] = GBoost_pred\nGBoost_pred2 = np.exp(GBoost.predict(train_df))\npredict_df2[\"GBoost\"] = GBoost_pred2\n\nmodel_xgb.fit(train_df, y_train)\nmodel_xgb_pred = np.exp(model_xgb.predict(test_df))\naverage_df2[\"model_xgb\"] = model_xgb_pred\nmodel_xgb_pred2 = np.exp(model_xgb.predict(train_df))\npredict_df2[\"model_xgb\"] = model_xgb_pred2\n\nmodel_lgb.fit(train_df, y_train)\nmodel_lgb_pred = np.exp(model_lgb.predict(test_df))\naverage_df2[\"model_lgb\"] = model_lgb_pred\nmodel_lgb_pred2 = np.exp(model_lgb.predict(train_df))\npredict_df2[\"model_lgb\"] = model_lgb_pred2\n\n#平均を求める\naverage_df2[\"Ave\"] = average_df.mean(axis=1) \npredict_df2[\"Ave\"] = predict_df.mean(axis=1)\naverage_df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"error2: {}\".format(error(predict_df2[\"Ave\"].values , y_train )))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#提出用のデータ作成\n\n#sample_submission[\"SalePrice\"] = average_df2[\"Ave\"]\n#sample_submission.to_csv('house_price30.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":",\"GarageCars\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"BsmtFinSF2\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\nprint(train_df.shape)\nprint(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}